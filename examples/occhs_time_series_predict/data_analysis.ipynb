{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functional import seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>physical_exam_conclusion</th>\n",
       "      <th>physical_exam_conclusion_detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>二氯甲烷_职业禁忌证;甲苯_其他疾病或异常;乙酸乙酯_其他疾病或异常;四氢呋喃_其他疾病或异...</td>\n",
       "      <td>二氯甲烷_慢性肝病;甲苯_舒张压异常;乙酸乙酯_舒张压异常;四氢呋喃_舒张压异常;异丙醇_舒...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>以上未提及的可导致职业病的其他化学因素_职业禁忌证;高温(高温作业)_职业禁忌证;乙酸_其他...</td>\n",
       "      <td>以上未提及的可导致职业病的其他化学因素_慢性肝病;高温(高温作业)_未控制的糖尿病;乙酸_谷...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>粉尘类_其他疾病或异常;噪声_职业禁忌证;高温(高温作业)_其他疾病或异常</td>\n",
       "      <td>粉尘类_超重,肝功能轻度升高,肺微小结节影（边界欠清）;噪声_高频段3000Hz，4000H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>二氯甲烷_职业禁忌证;甲苯_其他疾病或异常;乙酸乙酯_其他疾病或异常;四氢呋喃_其他疾病或异...</td>\n",
       "      <td>二氯甲烷_慢性肝病;甲苯_谷丙转氨酶异常;乙酸乙酯_谷丙转氨酶异常;四氢呋喃_谷丙转氨酶异常...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>二氯甲烷_职业禁忌证;甲苯_其他疾病或异常;乙酸乙酯_其他疾病或异常;四氢呋喃_其他疾病或异...</td>\n",
       "      <td>二氯甲烷_慢性肝病;甲苯_肝胆脾异常;乙酸乙酯_肝胆脾异常;四氢呋喃_肝胆脾异常;异丙醇_肝...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            physical_exam_conclusion  \\\n",
       "0  二氯甲烷_职业禁忌证;甲苯_其他疾病或异常;乙酸乙酯_其他疾病或异常;四氢呋喃_其他疾病或异...   \n",
       "1  以上未提及的可导致职业病的其他化学因素_职业禁忌证;高温(高温作业)_职业禁忌证;乙酸_其他...   \n",
       "2              粉尘类_其他疾病或异常;噪声_职业禁忌证;高温(高温作业)_其他疾病或异常   \n",
       "3  二氯甲烷_职业禁忌证;甲苯_其他疾病或异常;乙酸乙酯_其他疾病或异常;四氢呋喃_其他疾病或异...   \n",
       "4  二氯甲烷_职业禁忌证;甲苯_其他疾病或异常;乙酸乙酯_其他疾病或异常;四氢呋喃_其他疾病或异...   \n",
       "\n",
       "                     physical_exam_conclusion_detail  \n",
       "0  二氯甲烷_慢性肝病;甲苯_舒张压异常;乙酸乙酯_舒张压异常;四氢呋喃_舒张压异常;异丙醇_舒...  \n",
       "1  以上未提及的可导致职业病的其他化学因素_慢性肝病;高温(高温作业)_未控制的糖尿病;乙酸_谷...  \n",
       "2  粉尘类_超重,肝功能轻度升高,肺微小结节影（边界欠清）;噪声_高频段3000Hz，4000H...  \n",
       "3  二氯甲烷_慢性肝病;甲苯_谷丙转氨酶异常;乙酸乙酯_谷丙转氨酶异常;四氢呋喃_谷丙转氨酶异常...  \n",
       "4  二氯甲烷_慢性肝病;甲苯_肝胆脾异常;乙酸乙酯_肝胆脾异常;四氢呋喃_肝胆脾异常;异丙醇_肝...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(\"./cache/occupational_category_match.csv\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拆分为键值对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'其他疾病或异常', '复查', '疑似职业病', '目前未见异常', '职业禁忌证'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq(original_df[\"physical_exam_conclusion\"].values).map(lambda x: seq(x.split(\";\")).map(lambda x: x.split(\"_\")[1]).set()).flatten().set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_2nd(x):\n",
    "    if x is not None:\n",
    "        list_1st = seq(x.split(\";\")).filter(lambda x: x!=\"\")\n",
    "        try:\n",
    "            res = list_1st.map(lambda x: (x.split(\"_\")[0], x.split(\"_\")[1]) if len(x.split(\"_\"))==2 else None).filter(lambda x: x is not None).dict()\n",
    "            return res\n",
    "        except IndexError:\n",
    "            print(x)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df[\"physical_exam_conclusion_dict\"] = original_df[\"physical_exam_conclusion\"].apply(split_2nd)\n",
    "original_df[\"physical_exam_conclusion_detail_dict\"] = original_df[\"physical_exam_conclusion_detail\"].apply(split_2nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匹配相同键，拼接值为新的字典\n",
    "\n",
    "如需保留具体危害因素以进行更多分析，需加入harzard字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_match(row):\n",
    "    dict1 = row[\"physical_exam_conclusion_dict\"]\n",
    "    dict2 = row[\"physical_exam_conclusion_detail_dict\"]\n",
    "    merged_dict = {}\n",
    "    common_keys = set(dict1.keys()).intersection(dict2.keys())\n",
    "    for key in common_keys:\n",
    "        # merged_dict[key] = (dict1[key], dict2[key])\n",
    "        merged_dict.update({dict1[key]:dict2[key]})\n",
    "    return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    {'职业禁忌证': '慢性肝病', '其他疾病或异常': '舒张压异常'}\n",
       "1             {'职业禁忌证': '慢性肝病', '其他疾病或异常': '谷草转氨酶（AST）异常'}\n",
       "2        {'其他疾病或异常': '超重,肝功能轻度升高,肺微小结节影（边界欠清）', '职业禁忌证'...\n",
       "3                  {'职业禁忌证': '慢性肝病', '其他疾病或异常': '谷丙转氨酶异常'}\n",
       "4                    {'职业禁忌证': '慢性肝病', '其他疾病或异常': '肝胆脾异常'}\n",
       "                               ...                        \n",
       "40507    {'职业禁忌证': '除噪声外各种原因引起的永久性感音神经性听力损失（500Hz，l000H...\n",
       "40508    {'职业禁忌证': '各种原因引起永久性感音神经性听力损失（500Hz、1000Hz和200...\n",
       "40509    {'职业禁忌证': '各种原因引起永久性感音神经性听力损失（500Hz、1000Hz和200...\n",
       "40510    {'职业禁忌证': '各种原因引起永久性感音神经性听力损失（500Hz、1000Hz和200...\n",
       "40511                  {'职业禁忌证': '任一耳传导性耳聋，平均语频听力损失≥41dB'}\n",
       "Length: 40512, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_se = original_df.apply(type_match, axis=1)\n",
    "disease_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去重，保留职业禁忌症进行关键词归类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = []\n",
    "for object in disease_se:\n",
    "    disease_desc = seq(object.items()).filter(lambda x: x[0]==\"职业禁忌证\").map(lambda x: x[1])[0]\n",
    "    # print(disease_desc)\n",
    "    final_res.append(disease_desc)\n",
    "final_res = set(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['多发性周围神经病,未控制的糖尿病', '多发性周围神经病', '视网膜及视神经病', '中枢神经系统器质性疾病,高频段3000Hz，4000Hz，6000Hz双耳平均听阈≥40dB', '任一耳传导性耳聋，平均语频听力损失≥41dB,多发性周围神经病', '中枢神经系统及周围神经系统疾病和病史', '中枢神经系统器质性疾病', '腋臭，头癖，泛发性体癣，疥疮，慢性湿疹，神经性皮炎，白癜风，银屑病', '视网膜及视神经病,伴肺功能损害的疾病']\n"
     ]
    }
   ],
   "source": [
    "print(seq(final_res).filter(lambda x: \"神经\" in x and \"神经性听力损失\" not in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCCUPATIONAL_DISEASE_TYPE_DICT = {\n",
    "    \"听力\": \"职业性听力损伤\",\n",
    "    \"听阈\": \"职业性听力损伤\",\n",
    "    \"聋\": \"职业性听力损伤\",\n",
    "    \"皮肤\": \"职业性皮肤病\",\n",
    "    \"疹\": \"职业性皮肤病\",\n",
    "    \"血\": \"职业性心血管系统系统疾病\",\n",
    "    \"心脏\": \"职业性心血管系统系统疾病\",\n",
    "    \"心电\": \"职业性心血管系统系统疾病\",\n",
    "    \"呼吸系统\": \"职业性呼吸系统疾病\",\n",
    "    \"肺\": \"职业性呼吸系统疾病\",\n",
    "    \"支气管\": \"职业性呼吸系统疾病\",\n",
    "    \"嗅\": \"职业性呼吸系统疾病\",\n",
    "    \"鼻\": \"职业性呼吸系统疾病\",\n",
    "    \"内分泌\": \"职业性内分泌系统疾病\",\n",
    "    \"甲状腺\": \"职业性内分泌系统疾病\",\n",
    "    \"泌尿\": \"职业性泌尿生殖系统疾病\",\n",
    "    \"糖尿\": \"职业性泌尿生殖系统疾病\",\n",
    "    \"生殖\": \"职业性泌尿生殖系统疾病\",\n",
    "    \"神经系统\": \"职业性神经系统疾病\",\n",
    "    \"周围神经病\": \"职业性神经系统疾病\",\n",
    "    \"视力\": \"职业性眼病\",\n",
    "    \"色\": \"职业性眼病\",\n",
    "    \"盲\": \"职业性眼病\",\n",
    "    \"角膜\": \"职业性眼病\",\n",
    "    \"白内障\": \"职业性眼病\",\n",
    "    \"肝\": \"职业性中毒性肝病\",\n",
    "    \"肾\": \"职业性中毒性肾病\",\n",
    "    \"肿瘤\": \"职业性肿瘤\",\n",
    "    \"放射性\": \"职业性放射性疾病\",\n",
    "    \"骨\": \"职业性骨关节疾病\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 职业病种类打标测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def disease_mark(x):\n",
    "    res = []\n",
    "    for key, value in OCCUPATIONAL_DISEASE_TYPE_DICT.items():\n",
    "        if key in x:\n",
    "            res.append(value)\n",
    "    return \",\".join(set(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          职业性中毒性肝病\n",
       "1              职业性泌尿生殖系统疾病,职业性中毒性肝病\n",
       "2        职业性中毒性肝病,职业性听力损伤,职业性呼吸系统疾病\n",
       "3                          职业性中毒性肝病\n",
       "4                          职业性中毒性肝病\n",
       "                    ...            \n",
       "40507                       职业性听力损伤\n",
       "40508                       职业性听力损伤\n",
       "40509                       职业性听力损伤\n",
       "40510                       职业性听力损伤\n",
       "40511                       职业性听力损伤\n",
       "Name: physical_exam_conclusion_detail, Length: 40512, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df[\"physical_exam_conclusion_detail\"].apply(disease_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 功能代码测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Text  cat  dog\n",
      "0                I like cats    1    0\n",
      "1                I like dogs    0    1\n",
      "2  I like both cats and dogs    1    1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# 创建示例 DataFrame\n",
    "data = {'Text': ['I like cats', 'I like dogs', 'I like both cats and dogs'],\n",
    "        'Label': [['cat'], ['dog'], ['cat', 'dog']]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 对标签进行二进制编码\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_labels = pd.DataFrame(mlb.fit_transform(df['Label']), columns=mlb.classes_)\n",
    "\n",
    "# 将编码后的标签与原始数据合并\n",
    "encoded_df = pd.concat([df['Text'], encoded_labels], axis=1)\n",
    "\n",
    "# 打印编码结果\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from catboost.utils import eval_metric\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_multilabel_classification(n_samples=500, n_features=20, n_classes=5, random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "train_pool = Pool(X_train, Y_train)\n",
    "test_pool = Pool(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>institution_code</th>\n",
       "      <th>institution_location_code</th>\n",
       "      <th>organization_location_code</th>\n",
       "      <th>organization_enterprise_type</th>\n",
       "      <th>organization_industry_type</th>\n",
       "      <th>organization_industry_type_code</th>\n",
       "      <th>organization_enterprise_scale</th>\n",
       "      <th>employing_unit_enterprise_type</th>\n",
       "      <th>employing_unit_industry_type</th>\n",
       "      <th>employing_unit_enterprise_scale</th>\n",
       "      <th>...</th>\n",
       "      <th>hazard_code_0</th>\n",
       "      <th>hazard_code_1</th>\n",
       "      <th>hazard_code_2</th>\n",
       "      <th>hazard_code_3</th>\n",
       "      <th>hazard_code_4</th>\n",
       "      <th>hazard_code_5</th>\n",
       "      <th>hazard_code_6</th>\n",
       "      <th>hazard_code_7</th>\n",
       "      <th>hazard_code_8</th>\n",
       "      <th>hazard_code_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330502053</td>\n",
       "      <td>33050200</td>\n",
       "      <td>330502000</td>\n",
       "      <td>私营股份有限(公司)</td>\n",
       "      <td>绝缘制品制造</td>\n",
       "      <td>3834</td>\n",
       "      <td>大</td>\n",
       "      <td>私营股份有限(公司)</td>\n",
       "      <td>绝缘制品制造</td>\n",
       "      <td>大</td>\n",
       "      <td>...</td>\n",
       "      <td>12005</td>\n",
       "      <td>12166.0</td>\n",
       "      <td>12443.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330402036</td>\n",
       "      <td>33040200</td>\n",
       "      <td>330402000</td>\n",
       "      <td>股份有限(公司)</td>\n",
       "      <td>其他电子设备制造</td>\n",
       "      <td>3990</td>\n",
       "      <td>大</td>\n",
       "      <td>股份有限(公司)</td>\n",
       "      <td>其他电子设备制造</td>\n",
       "      <td>大</td>\n",
       "      <td>...</td>\n",
       "      <td>13001</td>\n",
       "      <td>11999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330105010</td>\n",
       "      <td>33010500</td>\n",
       "      <td>330114007</td>\n",
       "      <td>私营有限责任(公司)</td>\n",
       "      <td>生物药品制造</td>\n",
       "      <td>2761</td>\n",
       "      <td>中</td>\n",
       "      <td>私营有限责任(公司)</td>\n",
       "      <td>生物药品制造</td>\n",
       "      <td>中</td>\n",
       "      <td>...</td>\n",
       "      <td>12217</td>\n",
       "      <td>12032.0</td>\n",
       "      <td>11999.0</td>\n",
       "      <td>13002.0</td>\n",
       "      <td>13001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330481001</td>\n",
       "      <td>33048100</td>\n",
       "      <td>330481112</td>\n",
       "      <td>中外合资</td>\n",
       "      <td>光伏设备及元器件制造</td>\n",
       "      <td>3825</td>\n",
       "      <td>大</td>\n",
       "      <td>中外合资</td>\n",
       "      <td>光伏设备及元器件制造</td>\n",
       "      <td>大</td>\n",
       "      <td>...</td>\n",
       "      <td>13001</td>\n",
       "      <td>12032.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>330104025</td>\n",
       "      <td>33010200</td>\n",
       "      <td>330122105</td>\n",
       "      <td>私营有限责任(公司)</td>\n",
       "      <td>金属废料和碎屑加工处理</td>\n",
       "      <td>4210</td>\n",
       "      <td>小</td>\n",
       "      <td>私营有限责任(公司)</td>\n",
       "      <td>金属废料和碎屑加工处理</td>\n",
       "      <td>小</td>\n",
       "      <td>...</td>\n",
       "      <td>12035</td>\n",
       "      <td>13002.0</td>\n",
       "      <td>11001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 697 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   institution_code  institution_location_code  organization_location_code  \\\n",
       "0         330502053                   33050200                   330502000   \n",
       "1         330402036                   33040200                   330402000   \n",
       "2         330105010                   33010500                   330114007   \n",
       "3         330481001                   33048100                   330481112   \n",
       "4         330104025                   33010200                   330122105   \n",
       "\n",
       "  organization_enterprise_type organization_industry_type  \\\n",
       "0                   私营股份有限(公司)                     绝缘制品制造   \n",
       "1                     股份有限(公司)                   其他电子设备制造   \n",
       "2                   私营有限责任(公司)                     生物药品制造   \n",
       "3                         中外合资                 光伏设备及元器件制造   \n",
       "4                   私营有限责任(公司)                金属废料和碎屑加工处理   \n",
       "\n",
       "   organization_industry_type_code organization_enterprise_scale  \\\n",
       "0                             3834                             大   \n",
       "1                             3990                             大   \n",
       "2                             2761                             中   \n",
       "3                             3825                             大   \n",
       "4                             4210                             小   \n",
       "\n",
       "  employing_unit_enterprise_type employing_unit_industry_type  \\\n",
       "0                     私营股份有限(公司)                       绝缘制品制造   \n",
       "1                       股份有限(公司)                     其他电子设备制造   \n",
       "2                     私营有限责任(公司)                       生物药品制造   \n",
       "3                           中外合资                   光伏设备及元器件制造   \n",
       "4                     私营有限责任(公司)                  金属废料和碎屑加工处理   \n",
       "\n",
       "  employing_unit_enterprise_scale  ...  hazard_code_0 hazard_code_1  \\\n",
       "0                               大  ...          12005       12166.0   \n",
       "1                               大  ...          13001       11999.0   \n",
       "2                               中  ...          12217       12032.0   \n",
       "3                               大  ...          13001       12032.0   \n",
       "4                               小  ...          12035       13002.0   \n",
       "\n",
       "  hazard_code_2 hazard_code_3 hazard_code_4 hazard_code_5 hazard_code_6  \\\n",
       "0       12443.0           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2       11999.0       13002.0       13001.0           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4       11001.0           NaN           NaN           NaN           NaN   \n",
       "\n",
       "  hazard_code_7  hazard_code_8  hazard_code_9  \n",
       "0           NaN            NaN            NaN  \n",
       "1           NaN            NaN            NaN  \n",
       "2           NaN            NaN            NaN  \n",
       "3           NaN            NaN            NaN  \n",
       "4           NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 697 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../occhs_single_label_classification/cache/preprocessed_data_set.csv\")\n",
    "special_cols = [122, 137, 155, 158, 197, 230, 299, 563, 566]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GLU_result',\n",
       " 'UncorrectedVisualAcuityLeft_result',\n",
       " 'VisualAcuityLeft_result',\n",
       " 'VisualAcuityRight_result',\n",
       " 'Neu100_result',\n",
       " 'UncorrectedVisualAcuity_LeftEye_result',\n",
       " 'CorrectedVisionLeft_result',\n",
       " 'UrineCalcium_result',\n",
       " 'UrineCreatinine_result']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[special_cols].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     25\u001b[0m                            loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiClass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 在测试集上进行预测\u001b[39;00m\n\u001b[0;32m     31\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\catboost\\core.py:5131\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5129\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, cat_features, text_features, embedding_features, \u001b[38;5;28;01mNone\u001b[39;00m, sample_weight, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, baseline, use_best_model,\n\u001b[0;32m   5132\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5133\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\catboost\\core.py:2341\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES \u001b[38;5;241m+\u001b[39m (Pool,)):\n\u001b[0;32m   2339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2341\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_train_params(\n\u001b[0;32m   2342\u001b[0m     X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, cat_features\u001b[38;5;241m=\u001b[39mcat_features, text_features\u001b[38;5;241m=\u001b[39mtext_features, embedding_features\u001b[38;5;241m=\u001b[39membedding_features,\n\u001b[0;32m   2343\u001b[0m     pairs\u001b[38;5;241m=\u001b[39mpairs, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, group_id\u001b[38;5;241m=\u001b[39mgroup_id, group_weight\u001b[38;5;241m=\u001b[39mgroup_weight,\n\u001b[0;32m   2344\u001b[0m     subgroup_id\u001b[38;5;241m=\u001b[39msubgroup_id, pairs_weight\u001b[38;5;241m=\u001b[39mpairs_weight, baseline\u001b[38;5;241m=\u001b[39mbaseline, use_best_model\u001b[38;5;241m=\u001b[39muse_best_model,\n\u001b[0;32m   2345\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39meval_set, verbose\u001b[38;5;241m=\u001b[39mverbose, logging_level\u001b[38;5;241m=\u001b[39mlogging_level, plot\u001b[38;5;241m=\u001b[39mplot, plot_file\u001b[38;5;241m=\u001b[39mplot_file,\n\u001b[0;32m   2346\u001b[0m     column_description\u001b[38;5;241m=\u001b[39mcolumn_description, verbose_eval\u001b[38;5;241m=\u001b[39mverbose_eval, metric_period\u001b[38;5;241m=\u001b[39mmetric_period,\n\u001b[0;32m   2347\u001b[0m     silent\u001b[38;5;241m=\u001b[39msilent, early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds, save_snapshot\u001b[38;5;241m=\u001b[39msave_snapshot,\n\u001b[0;32m   2348\u001b[0m     snapshot_file\u001b[38;5;241m=\u001b[39msnapshot_file, snapshot_interval\u001b[38;5;241m=\u001b[39msnapshot_interval, init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m   2349\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[0;32m   2350\u001b[0m )\n\u001b[0;32m   2351\u001b[0m params \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2352\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\catboost\\core.py:2222\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[0;32m   2219\u001b[0m text_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2220\u001b[0m embedding_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2222\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[0;32m   2223\u001b[0m                                sample_weight, group_id, group_weight, subgroup_id, pairs_weight,\n\u001b[0;32m   2224\u001b[0m                                baseline, column_description)\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_pool\u001b[38;5;241m.\u001b[39mis_empty_:\n\u001b[0;32m   2226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\catboost\\core.py:1438\u001b[0m, in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1438\u001b[0m     train_pool \u001b[38;5;241m=\u001b[39m Pool(X, y, cat_features\u001b[38;5;241m=\u001b[39mcat_features, text_features\u001b[38;5;241m=\u001b[39mtext_features, embedding_features\u001b[38;5;241m=\u001b[39membedding_features, pairs\u001b[38;5;241m=\u001b[39mpairs, weight\u001b[38;5;241m=\u001b[39msample_weight, group_id\u001b[38;5;241m=\u001b[39mgroup_id,\n\u001b[0;32m   1439\u001b[0m                       group_weight\u001b[38;5;241m=\u001b[39mgroup_weight, subgroup_id\u001b[38;5;241m=\u001b[39msubgroup_id, pairs_weight\u001b[38;5;241m=\u001b[39mpairs_weight, baseline\u001b[38;5;241m=\u001b[39mbaseline)\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_pool\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\catboost\\core.py:707\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_type(data)\n\u001b[1;32m--> 707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_empty(data)\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pairs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, PATH_TYPES) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(pairs, PATH_TYPES):\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata and pairs parameters should be the same types.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\catboost\\core.py:880\u001b[0m, in \u001b[0;36mPool._check_data_empty\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    878\u001b[0m data_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(data)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m data_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], Iterable):\n\u001b[0;32m    881\u001b[0m         data_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(data_shape \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;241m0\u001b[39m])]))\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# 创建示例 DataFrame\n",
    "data = {'Text': ['I like cats', 'I like dogs', 'I like both cats and dogs'],\n",
    "        'Label': [['cat'], ['dog'], ['cat', 'dog']]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 对标签进行多标签编码\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_labels = mlb.fit_transform(df['Label'])\n",
    "\n",
    "# 划分特征和标签\n",
    "X = df['Text']\n",
    "y = encoded_labels\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建 CatBoost 分类器\n",
    "model = CatBoostClassifier(iterations=100, depth=3, learning_rate=0.1, random_seed=42,\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 计算评估指标，例如准确率和 F1 分数\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 打印评估指标\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 Score:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
